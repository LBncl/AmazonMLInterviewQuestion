{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NAFLD.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMeeGpmhXAK0Gon++HEHsIq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LBncl/AmazonMLInterviewQuestion/blob/main/NAFLD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NAFLD PROJECT"
      ],
      "metadata": {
        "id": "JJ8ZGc1YjFZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "Pm6KDT1PjNKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import missingno as msno\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "JxvMeYS9iIA3"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning"
      ],
      "metadata": {
        "id": "AjLiQ0hJjR3a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "FcqiBWkdhpRx"
      },
      "outputs": [],
      "source": [
        "# Read in data\n",
        "df = pd.read_excel('master_with_nordic_and_multiBM.xlsx')\n",
        "\n",
        "# Check if dataFrame is empty\n",
        "if df.empty:\n",
        "    print('DataFrame is empty!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Subset data frame\n",
        "main_df = df.filter(items=['CPH_EV_AGE_CALC', 'TBL.PATIENT.INFO..PI_BL_GENDER', 'CPH_EV_CI_BMI_CALC', \n",
        "                         'TBL.ALL.EVENTS..AE_SF_ALCO_XS', 'insulin_resistance', 'hypertensive', 'waist_to_hip_ratio',\n",
        "                         'idf_metabolic_syndrome', 'eGFR', 'dyslipidaemia', 'fibroscan_stiffness_reliable',\n",
        "                         'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "                         'TBL.ALL.EVENTS..AE_BR_AST_iuL', 'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "                         'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "                         'TBL.ALL.EVENTS..AE_BR_PLT_109L', 'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "                         'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "                         'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC', 'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "                         'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "                         'TBL.ALL.EVENTS..AE_CD_OSA', 'LIT_NB_CK18_M30', 'LIT_NB_CK18_M65', 'LIT_NB_PRO_C3', 'LIT_NB_PRO_C6',\n",
        "                          'LIT_NB_ELF', 'FIB4', 'NFS', 'APRI', 'ADAPT', 'FIBC3', 'ABC3D', 'BARD', 'AST_ALT_Ratio', 'response_1', 'response_2', 'response_3a', 'response_3b', \n",
        "                             'response_4', 'response_5', 'response_6a', 'response_6b', 'response_7'])"
      ],
      "metadata": {
        "id": "1s4uX2A1i5_V"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_df.describe()"
      ],
      "metadata": {
        "id": "XAdTEnHfK_oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msno.bar(main_df)"
      ],
      "metadata": {
        "id": "xfNW-jzTjEQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "# Convert required variables to boolean and normlaise the remaining variables\n",
        "features = main_df.iloc[:, 0:35]\n",
        "\n",
        "# Loop to check for boolean columns\n",
        "for column in features:\n",
        "  if features[column].max() == 1:\n",
        "    features[column] = features[column].astype(bool)\n",
        "\n",
        "#cols_normalise = features.select_dtypes(include=[np.float64])\n",
        "#features[cols_normalise.columns] = preprocessing.scale(cols_normalise)"
      ],
      "metadata": {
        "id": "QCXqyL6Rj0Cq"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features.dtypes"
      ],
      "metadata": {
        "id": "gbXW3H6aDe38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter to only select basline event types\n",
        "features['CPH_EV_EVENT_TYPE'] = df['CPH_EV_EVENT_TYPE']\n",
        "is_Baseline = features['CPH_EV_EVENT_TYPE'] == 'Baseline'\n",
        "features_baseline = features[is_Baseline]\n",
        "features_baseline = features_baseline.iloc[: , :-1]\n",
        "features_baseline = features_baseline.reset_index()\n",
        "features_baseline = features_baseline.iloc[: , 1:]"
      ],
      "metadata": {
        "id": "nA-yM30qLk1F"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_baseline"
      ],
      "metadata": {
        "id": "om2CqQCUDW9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Imputation Strategies"
      ],
      "metadata": {
        "id": "nhKAAVJErIz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports for imputation functions\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "b9QfYn0OrOsJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Single imputation with mean to replace not a number (NaNs)\n",
        "def nan2mean(fdf):\n",
        "    cols = list(fdf.columns)\n",
        "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "    fdf=imp.fit_transform(fdf)\n",
        "    fdf = pd.DataFrame(fdf, columns=cols)\n",
        "    return fdf"
      ],
      "metadata": {
        "id": "XdhqTVx5rXQ-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Single imputation with median to replace not a number (NaNs)\n",
        "def nan2median(fdf):\n",
        "    cols = list(fdf.columns)\n",
        "    imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
        "    fdf=imp.fit_transform(fdf)\n",
        "    fdf = pd.DataFrame(fdf, columns=cols)\n",
        "    return fdf"
      ],
      "metadata": {
        "id": "k-PByFl_rexy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Single imputation with most_frequent to replace not a number (NaNs)\n",
        "def nan2most_frequent(fdf):\n",
        "    cols = list(fdf.columns)\n",
        "    imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
        "    fdf=imp.fit_transform(fdf)\n",
        "    fdf = pd.DataFrame(fdf, columns=cols)\n",
        "    return fdf"
      ],
      "metadata": {
        "id": "a6mf5HU_rhvF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiple Imputation by chained equation linear regression\n",
        "def nan2mice(fdf):\n",
        "    cols = list(fdf.columns)\n",
        "    lr = LinearRegression()\n",
        "    imp = IterativeImputer(estimator=lr,missing_values=np.nan, max_iter=50, imputation_order='roman',random_state=0)\n",
        "    fdf=imp.fit_transform(fdf)\n",
        "    fdf = pd.DataFrame(fdf, columns=cols)\n",
        "    return fdf"
      ],
      "metadata": {
        "id": "vy61XAe0r76R"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imputation by K neasrest neighbours\n",
        "def nan2knn(fdf):\n",
        "    cols = list(fdf.columns)\n",
        "    imp = KNNImputer(n_neighbors=2, weights=\"distance\")\n",
        "    fdf=imp.fit_transform(fdf)\n",
        "    fdf = pd.DataFrame(fdf, columns=cols)\n",
        "    return fdf"
      ],
      "metadata": {
        "id": "3OCLAwGRuUyu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to compare the denisty of raw vs imputed data\n",
        "def compare_denisty(column_name, fdf):\n",
        "  d = {'raw': preprocessing.scale(features_baseline[column_name]), 'imputed': fdf[column_name]}\n",
        "  fdata = pd.DataFrame(data=d)\n",
        "\n",
        "  # calling density() to make multiple density plot \n",
        "  fig, axes = plt.subplots(1, 2)\n",
        "  fig.suptitle('Raw vs Imputed Desity Plots')\n",
        "  fdata['raw'].plot.density(ax=axes[0], figsize = (15, 7))\n",
        "  fdata['imputed'].plot.density(ax=axes[1], figsize = (15, 7), color='red')\n",
        "\n",
        "  axes[0].set_title('Raw Data')\n",
        "  axes[1].set_title('Imputed Data')\n",
        "\n",
        "  axes[0].set_xlabel(column_name)\n",
        "  axes[1].set_xlabel(column_name)\n",
        "\n",
        "\n",
        "  return fdata"
      ],
      "metadata": {
        "id": "68Vp9MBFvNFd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model evaluation"
      ],
      "metadata": {
        "id": "gfAnUz9My8oK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new imputed datasets\n",
        "featuresKNN = nan2knn(features_baseline)\n",
        "featuresMean = nan2mean(features_baseline)\n",
        "featuresMedian = nan2median(features_baseline)\n",
        "featuresMICE = nan2mice(features_baseline)\n",
        "featuresMostFrq = nan2most_frequent(features_baseline)\n",
        "featuresMostFrq = featuresMostFrq.apply(pd.to_numeric)\n",
        "\n",
        "# Create list of all imputation strategies\n",
        "imputed_features = [featuresKNN,featuresMean,featuresMedian,featuresMICE,featuresMostFrq]\n",
        "imputed_features_names = ['featuresKNN','featuresMean','featuresMedian','featuresMICE','featuresMostFrq']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-pBTzt7UmCD",
        "outputId": "a41cb95a-d4fd-4f73-b5b8-fcdd483a3c6e"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/impute/_iterative.py:701: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pull response from data frame with only baseline observations\n",
        "y = main_df[\"response_1\"]\n",
        "response = pd.DataFrame({'y':y, 'Baseline':features['CPH_EV_EVENT_TYPE']})\n",
        "is_Baseline = response['Baseline'] == 'Baseline'\n",
        "response = response[is_Baseline]\n",
        "response = response['y']\n",
        "\n",
        "# Add response variable to all imputed datasets and remove observations with NaN responses\n",
        "for df in imputed_features:\n",
        "  df['response'] = response\n",
        "  df = df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "ffeKd5yvPvaC"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# function to generate test/train split\n",
        "def train_test (fdf):\n",
        "  # Split data into test and trian\n",
        "  X_train, X_test, y_train, y_test = train_test_split(fdf.iloc[:, 0:35], fdf.iloc[: , -1], test_size=0.30, random_state=0)\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "Kq-Sr1bTUoc2"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "jVRfmq9F2NqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Logistic Regression model\n",
        "# Implement the model\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# hyperparameters, penalty values chosen to work with all solvers\n",
        "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
        "penalty = ['l2']\n",
        "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
        "\n",
        "# define grid search\n",
        "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=logreg, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "\n",
        "for i in range(len(imputed_features)):\n",
        "  df = imputed_features[i]\n",
        "  grid_result = grid_search.fit(df.iloc[:, 0:35], df.iloc[: , -1])\n",
        "\n",
        "  # summarize results\n",
        "  print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_), imputed_features_names[i])"
      ],
      "metadata": {
        "id": "8NW-mkLdzB43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "76411c59-3034-430c-8313-9443327b43ff"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.606310 using {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'} featuresKNN\n",
            "Best: 0.605561 using {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'} featuresMean\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-162-93e38b4038a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimputed_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimputed_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m   \u001b[0;31m# summarize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM"
      ],
      "metadata": {
        "id": "JlZ4HqMH2TM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# SVM model\n",
        "def model_SVM(fdf, response):\n",
        "  # Pull the correct resposne variable from the dataframe\n",
        "  y = main_df[response]\n",
        "  # Remove all rows with missing observations\n",
        "  X = fdf\n",
        "  X['y'] = y\n",
        "  X = fdf.dropna()\n",
        "  # Split data into test and trian\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X.iloc[:, 0:35], X.iloc[: , -1],test_size=0.20, random_state=0)\n",
        "  # Implement the model\n",
        "  clf = svm.SVC(kernel='linear')\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "\n",
        "  #use model to predict probability that given y value is 1\n",
        "  y_pred_proba = clf.predict_proba(X_test)[::,1]\n",
        "\n",
        "  #calculate AUC of model\n",
        "  auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "  #print AUC score\n",
        "  print(auc)\n",
        "\n",
        "  # Calculate F-score\n",
        "  report = classification_report(y_test, y_pred)\n",
        "  print(report)\n",
        "\n",
        "  return y_pred"
      ],
      "metadata": {
        "id": "0qJ1-H9m_5Z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost "
      ],
      "metadata": {
        "id": "RdtRB2_w29RB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Implement the model\n",
        "model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
        "\n",
        "for i in range(len(imputed_features)):\n",
        "  df = imputed_features[i]\n",
        "  X_train, X_test, y_train, y_test = train_test(df)\n",
        "  model.fit(X_train, y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  print(accuracy)\n",
        "\n"
      ],
      "metadata": {
        "id": "Ow2S3ALZFPDK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88eabeba-18be-48c3-ea13-f2a5bc1f9bd0"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5952529668956902\n",
            "0.5983760149906309\n",
            "0.599000624609619\n",
            "0.5983760149906309\n",
            "0.6083697688944409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "I3JKdx8O4p5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "def model_RF(fdf, response):\n",
        "  # Pull the correct resposne variable from the dataframe\n",
        "  y = main_df[response]\n",
        "  # Remove all rows with missing observations\n",
        "  X = fdf\n",
        "  X['y'] = y\n",
        "  X = fdf.dropna()\n",
        "  # Split data into test and trian\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X.iloc[:, 0:35], X.iloc[: , -1], test_size=0.20, random_state=0)\n",
        "  # Implement the model\n",
        "  regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
        "  regressor.fit(X_train, y_train)\n",
        "  y_pred = regressor.predict(X_test)\n",
        "\n",
        "  #use model to predict probability that given y value is 1\n",
        "  y_pred_proba = regressor.predict_proba(X_test)[::,1]\n",
        "\n",
        "  #calculate AUC of model\n",
        "  auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "  #print AUC score\n",
        "  print(auc)\n",
        "\n",
        "  # Calculate F-score\n",
        "  report = classification_report(y_test, y_pred)\n",
        "  print(report)\n",
        "\n",
        "  return y_pred"
      ],
      "metadata": {
        "id": "x5u3tH-14vNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Imports"
      ],
      "metadata": {
        "id": "HBvKTEZ5UUZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "6Ls5dT7oUYHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline"
      ],
      "metadata": {
        "id": "LWqwTTKk7v9v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imputation and Target Variable Selection"
      ],
      "metadata": {
        "id": "9liHjz7i9nf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compare_denisty(\"CPH_EV_AGE_CALC\",featuresKNN)"
      ],
      "metadata": {
        "id": "Y18vqJ-RKnND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare Performance for All Models"
      ],
      "metadata": {
        "id": "n9cE1mHW9sCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_model(arg):\n",
        "  # Select target responses\n",
        "  response = arg\n",
        "\n",
        "  # Apply model to all imputed data frames\n",
        "  for i in range(5):\n",
        "    x = imputed_features[i]\n",
        "    model_SVM(x, response)"
      ],
      "metadata": {
        "id": "RDgdZpZxQLsm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}