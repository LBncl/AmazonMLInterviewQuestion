{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NAFLD.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Pm6KDT1PjNKB",
        "AjLiQ0hJjR3a",
        "nhKAAVJErIz-",
        "gfAnUz9My8oK",
        "spD21lRw-xjx",
        "I3JKdx8O4p5E",
        "HBvKTEZ5UUZ0",
        "9liHjz7i9nf0",
        "dI43cWj4blmP",
        "-PBHB5Ohbsb4",
        "Eak0dOKfeRe7"
      ],
      "authorship_tag": "ABX9TyMshTDZvg/Pxn6lENyIURzF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LBncl/AmazonMLInterviewQuestion/blob/main/NAFLD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NAFLD PROJECT"
      ],
      "metadata": {
        "id": "JJ8ZGc1YjFZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "Pm6KDT1PjNKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import missingno as msno\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "JxvMeYS9iIA3"
      },
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning"
      ],
      "metadata": {
        "id": "AjLiQ0hJjR3a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 350,
      "metadata": {
        "id": "FcqiBWkdhpRx"
      },
      "outputs": [],
      "source": [
        "# Read in data\n",
        "df_raw = pd.read_excel('master_with_nordic_and_multiBM.xlsx')\n",
        "\n",
        "# Check if dataFrame is empty\n",
        "if df_raw.empty:\n",
        "    print('DataFrame is empty!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Subset data frame\n",
        "main_df = df_raw.filter(items=['CPH_EV_AGE_CALC', 'TBL.PATIENT.INFO..PI_BL_GENDER', 'CPH_EV_CI_BMI_CALC', \n",
        "                         'TBL.ALL.EVENTS..AE_SF_ALCO_XS', 'insulin_resistance', 'hypertensive', 'waist_to_hip_ratio',\n",
        "                         'idf_metabolic_syndrome', 'eGFR', 'dyslipidaemia', 'fibroscan_stiffness_reliable',\n",
        "                         'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "                         'TBL.ALL.EVENTS..AE_BR_AST_iuL', 'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "                         'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "                         'TBL.ALL.EVENTS..AE_BR_PLT_109L', 'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "                         'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "                         'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC', 'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "                         'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "                         'TBL.ALL.EVENTS..AE_CD_OSA', 'LIT_NB_CK18_M30', 'LIT_NB_CK18_M65', 'LIT_NB_PRO_C3', 'LIT_NB_PRO_C6',\n",
        "                          'LIT_NB_ELF', 'FIB4', 'NFS', 'APRI', 'ADAPT', 'FIBC3', 'ABC3D', 'BARD', 'AST_ALT_Ratio', 'response_3b','CPH_EV_EVENT_TYPE'])"
      ],
      "metadata": {
        "id": "1s4uX2A1i5_V"
      },
      "execution_count": 433,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_df.describe()"
      ],
      "metadata": {
        "id": "XAdTEnHfK_oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_df.dtypes"
      ],
      "metadata": {
        "id": "npDox8CZF7ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "msno.bar(main_df)"
      ],
      "metadata": {
        "id": "xfNW-jzTjEQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove duplicates\n",
        "print(main_df.shape)\n",
        "main_df = main_df.drop_duplicates()\n",
        "print(main_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlSt0PZasBlg",
        "outputId": "00eae015-2b93-4042-95b5-f1a2a4167dde"
      },
      "execution_count": 434,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14236, 37)\n",
            "(13772, 37)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert required variables to boolean \n",
        "features_raw = main_df\n",
        "\n",
        "# Loop to check for boolean columns\n",
        "for column in features_raw.iloc[:, 0:36]:\n",
        "  if features_raw[column].max() == 1 and features_raw[column].min() == 0:\n",
        "    features_raw[column] = features_raw[column].astype(bool)"
      ],
      "metadata": {
        "id": "QCXqyL6Rj0Cq"
      },
      "execution_count": 435,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_raw.dtypes"
      ],
      "metadata": {
        "id": "gLPRAVzQGHnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_raw"
      ],
      "metadata": {
        "id": "LlWcWs-dNSqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter to only select baseline event types\n",
        "print(main_df.shape)\n",
        "features_raw['CPH_EV_EVENT_TYPE'] = features_raw['CPH_EV_EVENT_TYPE'].astype(str)\n",
        "features_raw = features_raw.loc[features_raw['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "print(features_raw.shape)"
      ],
      "metadata": {
        "id": "nA-yM30qLk1F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa610939-924c-4438-dfed-99f1c76ee768"
      },
      "execution_count": 442,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(13772, 37)\n",
            "(8991, 37)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_raw"
      ],
      "metadata": {
        "id": "TedwMvISSD-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove baseline column\n",
        "features_raw = features_raw.iloc[:, 0:36]"
      ],
      "metadata": {
        "id": "ioyKwAjBOBTr"
      },
      "execution_count": 443,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows where there is no response value and set value to Bool\n",
        "print(features_raw.shape)\n",
        "print(features_raw['response_3b'].isna().sum())\n",
        "features_raw = features_raw[features_raw['response_3b'].notna()]\n",
        "print(features_raw.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYmwQ2ExKiki",
        "outputId": "4c19222d-6241-4774-c6a5-88b5e48c964f"
      },
      "execution_count": 444,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8991, 36)\n",
            "0\n",
            "(8991, 36)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_baseline = features_raw"
      ],
      "metadata": {
        "id": "f4v9IEKB341n"
      },
      "execution_count": 445,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_baseline.plot(kind=\"box\", subplots=True, layout=(9,4), figsize=(50,50))"
      ],
      "metadata": {
        "id": "hGZ1cCN5CFeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_baseline.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6r24Gl-Q6aQc",
        "outputId": "6e858792-53b7-4bf4-a7d0-4013748bce88"
      },
      "execution_count": 446,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CPH_EV_AGE_CALC                           float64\n",
              "TBL.PATIENT.INFO..PI_BL_GENDER               bool\n",
              "CPH_EV_CI_BMI_CALC                        float64\n",
              "TBL.ALL.EVENTS..AE_SF_ALCO_XS                bool\n",
              "insulin_resistance                           bool\n",
              "hypertensive                                 bool\n",
              "waist_to_hip_ratio                        float64\n",
              "idf_metabolic_syndrome                       bool\n",
              "eGFR                                      float64\n",
              "dyslipidaemia                                bool\n",
              "fibroscan_stiffness_reliable              float64\n",
              "TBL.ALL.EVENTS..AE_BR_ALT_iuL             float64\n",
              "TBL.ALL.EVENTS..AE_BR_AST_iuL             float64\n",
              "TBL.ALL.EVENTS..AE_BR_GGT_iuL             float64\n",
              "TBL.ALL.EVENTS..AE_BR_FERR_ugL            float64\n",
              "TBL.ALL.EVENTS..AE_BR_PLT_109L            float64\n",
              "TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC    float64\n",
              "TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC      float64\n",
              "TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC        float64\n",
              "TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC     float64\n",
              "TBL.ALL.EVENTS..AE_BR_IGA                 float64\n",
              "TBL.ALL.EVENTS..AE_CD_OSA                    bool\n",
              "LIT_NB_CK18_M30                           float64\n",
              "LIT_NB_CK18_M65                           float64\n",
              "LIT_NB_PRO_C3                             float64\n",
              "LIT_NB_PRO_C6                             float64\n",
              "LIT_NB_ELF                                float64\n",
              "FIB4                                      float64\n",
              "NFS                                       float64\n",
              "APRI                                      float64\n",
              "ADAPT                                     float64\n",
              "FIBC3                                     float64\n",
              "ABC3D                                     float64\n",
              "BARD                                      float64\n",
              "AST_ALT_Ratio                             float64\n",
              "response_3b                                  bool\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 446
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "cols_normalise = features_baseline.select_dtypes(include=[np.float64])\n",
        "\n",
        "# Normalise Data\n",
        "scale = StandardScaler()\n",
        "features_baseline[cols_normalise.columns] = scale.fit_transform(cols_normalise)"
      ],
      "metadata": {
        "id": "8MZJ7whZ0FFh"
      },
      "execution_count": 447,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_baseline"
      ],
      "metadata": {
        "id": "om2CqQCUDW9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Imputation Strategies"
      ],
      "metadata": {
        "id": "nhKAAVJErIz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports for imputation functions\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "b9QfYn0OrOsJ"
      },
      "execution_count": 313,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Single imputation with mean to replace not a number (NaNs)\n",
        "def nan2mean(fdf):\n",
        "    cols = list(fdf.columns)\n",
        "    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "    fdf=imp.fit_transform(fdf)\n",
        "    fdf = pd.DataFrame(fdf, columns=cols)\n",
        "    return fdf"
      ],
      "metadata": {
        "id": "XdhqTVx5rXQ-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Single imputation with median to replace not a number (NaNs)\n",
        "def nan2median(fdf):\n",
        "    cols = list(fdf.columns)\n",
        "    imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
        "    fdf=imp.fit_transform(fdf)\n",
        "    fdf = pd.DataFrame(fdf, columns=cols)\n",
        "    return fdf"
      ],
      "metadata": {
        "id": "k-PByFl_rexy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Single imputation with most_frequent to replace not a number (NaNs)\n",
        "def nan2most_frequent(fdf):\n",
        "    cols = list(fdf.columns)\n",
        "    imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
        "    fdf=imp.fit_transform(fdf)\n",
        "    fdf = pd.DataFrame(fdf, columns=cols)\n",
        "    return fdf"
      ],
      "metadata": {
        "id": "a6mf5HU_rhvF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiple Imputation by chained equation linear regression\n",
        "def nan2mice(fdf):\n",
        "    cols = list(fdf.columns)\n",
        "    lr = LinearRegression()\n",
        "    imp = IterativeImputer(estimator=lr,missing_values=np.nan, max_iter=50, imputation_order='roman',random_state=0)\n",
        "    fdf=imp.fit_transform(fdf)\n",
        "    fdf = pd.DataFrame(fdf, columns=cols)\n",
        "    return fdf"
      ],
      "metadata": {
        "id": "vy61XAe0r76R"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imputation by K neasrest neighbours\n",
        "def nan2knn(fdf):\n",
        "    cols = list(fdf.columns)\n",
        "    imp = KNNImputer(n_neighbors=2, weights=\"distance\")\n",
        "    fdf=imp.fit_transform(fdf)\n",
        "    fdf = pd.DataFrame(fdf, columns=cols)\n",
        "    return fdf"
      ],
      "metadata": {
        "id": "3OCLAwGRuUyu"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model evaluation"
      ],
      "metadata": {
        "id": "gfAnUz9My8oK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new imputed datasets\n",
        "featuresKNN = nan2knn(features_baseline)\n",
        "featuresMean = nan2mean(features_baseline)\n",
        "featuresMedian = nan2median(features_baseline)\n",
        "featuresMICE = nan2mice(features_baseline)\n",
        "featuresMostFrq = nan2most_frequent(features_baseline)\n",
        "featuresMostFrq = featuresMostFrq.apply(pd.to_numeric)\n",
        "\n",
        "# Create list of all imputation strategies\n",
        "imputed_features = [featuresKNN,featuresMean,featuresMedian,featuresMICE,featuresMostFrq]\n",
        "imputed_features_names = ['featuresKNN','featuresMean','featuresMedian','featuresMICE','featuresMostFrq']"
      ],
      "metadata": {
        "id": "d-pBTzt7UmCD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2347001-5944-4f0b-e1a5-dedf2b3283ca"
      },
      "execution_count": 449,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/impute/_iterative.py:701: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "featuresKNN"
      ],
      "metadata": {
        "id": "0INKMsbdPITj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_name = \"CPH_EV_AGE_CALC\"\n",
        "\n",
        "d = {'raw': features_baseline[column_name], \n",
        "     'KNN Imputation': featuresKNN[column_name],\n",
        "     'Mean Imputation': featuresMean[column_name],\n",
        "     'Median Imputation': featuresMedian[column_name],\n",
        "     'MICE Imputation': featuresMICE[column_name],\n",
        "     'MostFrq Imputation': featuresMostFrq[column_name]}\n",
        "fdata = pd.DataFrame(data=d)\n",
        "\n",
        "# calling density() to make multiple density plot \n",
        "fig, axes = plt.subplots(1, 6)\n",
        "fig.suptitle('Raw vs Imputed Desity Plots')\n",
        "fdata['raw'].plot.density(ax=axes[0], figsize = (15, 7))\n",
        "fdata['Mean Imputation'].plot.density(ax=axes[1], figsize = (15, 7), color='red')\n",
        "fdata['Median Imputation'].plot.density(ax=axes[2], figsize = (15, 7), color='red')\n",
        "fdata['MICE Imputation'].plot.density(ax=axes[3], figsize = (15, 7), color='red')\n",
        "fdata['MostFrq Imputation'].plot.density(ax=axes[4], figsize = (15, 7), color='red')\n",
        "fdata['KNN Imputation'].plot.density(ax=axes[5], figsize = (15, 7), color='red')\n",
        "\n",
        "axes[0].set_title('Raw')\n",
        "axes[1].set_title('Mean Imputed')\n",
        "axes[2].set_title('Median Imputed')\n",
        "axes[3].set_title('MICE Imputed')\n",
        "axes[4].set_title('MostFrq Imputed')\n",
        "axes[5].set_title('KNN Imputed')\n",
        "\n",
        "axes[0].set_xlabel(column_name)\n",
        "axes[1].set_xlabel(column_name)\n",
        "axes[2].set_xlabel(column_name)\n",
        "axes[3].set_xlabel(column_name)\n",
        "axes[4].set_xlabel(column_name)\n",
        "axes[5].set_xlabel(column_name)"
      ],
      "metadata": {
        "id": "aJuBfUmdbsf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Outlier Identifcation"
      ],
      "metadata": {
        "id": "rlqeeuG7GT-M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Selection"
      ],
      "metadata": {
        "id": "spD21lRw-xjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install featurewiz"
      ],
      "metadata": {
        "id": "2_G7hct61W_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# automatic feature selection by using featurewiz package\n",
        "from featurewiz import featurewiz\n",
        "target = 'response'\n",
        "\n",
        "features_selected, train = featurewiz(featuresKNN, target, corr_limit=0.7, verbose=2, sep=\",\", header=0,test_data=\"\", feature_engg=\"\", category_encoders=\"\")"
      ],
      "metadata": {
        "id": "2QLRgCJbUBhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# function to generate test/train split\n",
        "def train_test (fdf):\n",
        "  # Split data into test and trian\n",
        "  X_train, X_test, y_train, y_test = train_test_split(fdf.iloc[:, 0:35], fdf.iloc[: , -1], test_size=0.30, random_state=0)\n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "Kq-Sr1bTUoc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter all data frames based upon best features\n",
        "featuresKNN = featuresKNN[features_selected]\n",
        "featuresMean = featuresMean[features_selected]\n",
        "featuresMedian = featuresMedian[features_selected]\n",
        "featuresMICE = featuresMICE[features_selected]\n",
        "featuresMostFrq = featuresMostFrq[features_selected]\n",
        "\n",
        "imputed_features = [featuresKNN,featuresMean,featuresMedian,featuresMICE,featuresMostFrq]\n",
        "\n",
        "# Add response variable to all imputed datasets\n",
        "for i in range(len(imputed_features)):\n",
        "  df = imputed_features[i]\n",
        "  df['response'] = response"
      ],
      "metadata": {
        "id": "lAFIE8xCAsj3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "featuresKNN"
      ],
      "metadata": {
        "id": "ea5cP4NQOlKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SMOTE"
      ],
      "metadata": {
        "id": "2goFqQYCYBSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check version number\n",
        "import imblearn\n",
        "print(imblearn.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrkXiOHcYN-F",
        "outputId": "f3cd3d14-6dab-49a7-bb9e-8976c6f3247b"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "# summarize class distributions for each imputed data set\n",
        "for df in imputed_features:\n",
        "  counter = collections.Counter(df['response'])\n",
        "  print(counter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTxm4sRLYS3h",
        "outputId": "069b44a3-e68f-4029-f058-261c47988798"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({1.0: 3403, 0.0: 1305})\n",
            "Counter({1.0: 3403, 0.0: 1305})\n",
            "Counter({1.0: 3403, 0.0: 1305})\n",
            "Counter({1.0: 3403, 0.0: 1305})\n",
            "Counter({1.0: 3403, 0.0: 1305})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# transform the dataset\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "over = SMOTE()\n",
        "under = RandomUnderSampler()\n",
        "steps = [('o', over), ('u', under)]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "\n",
        "X , y = pipeline.fit_resample(featuresMICE.iloc[:, 0:35] , featuresMICE.iloc[: , -1])"
      ],
      "metadata": {
        "id": "N3pHzoRcdGY5"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize the new class distribution\n",
        "counter = collections.Counter(y)\n",
        "print(counter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNiqaOtDez_b",
        "outputId": "d9240baa-89e3-4b70-cfda-fb2492e22e21"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({0.0: 3403, 1.0: 3403})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {
        "id": "jVRfmq9F2NqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Logistic Regression model\n",
        "# Implement the model\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# hyperparameters, penalty values chosen to work with all solvers\n",
        "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
        "penalty = ['l2']\n",
        "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
        "\n",
        "# define grid search\n",
        "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=logreg, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
        "\n",
        "# SMOTE\n",
        "over = SMOTE(sampling_strategy=0.4)\n",
        "under = RandomUnderSampler(sampling_strategy=1)\n",
        "steps = [('o', over), ('u', under)]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "\n",
        "for i in range(len(imputed_features)):\n",
        "  df = imputed_features[i]\n",
        "  X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 0:35], df['response_3b'], test_size=0.2, random_state=42)\n",
        "  \n",
        "  X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
        "\n",
        "  grid_result = grid_search.fit(X_train, y_train)\n",
        "  grid_predict = grid_result.predict(X_test)\n",
        "\n",
        "  # summarize results\n",
        "  print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_), imputed_features_names[i])\n",
        "  print(confusion_matrix(y_test, grid_predict))\n",
        "  print(classification_report(y_test, grid_predict))"
      ],
      "metadata": {
        "id": "8NW-mkLdzB43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM"
      ],
      "metadata": {
        "id": "JlZ4HqMH2TM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# fit a svm on an imbalanced classification dataset\n",
        "from numpy import mean\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# define model\n",
        "model = SVC(gamma='scale')\n",
        "# define evaluation procedure\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "for df in imputed_features:\n",
        "  X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 0:35], df['response_3b'], test_size=0.2, random_state=0)\n",
        "  # evaluate model\n",
        "  scores = cross_val_score(model, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
        "  # summarize performance\n",
        "  print('Mean ROC AUC: %.3f' % mean(scores))\n",
        "\n"
      ],
      "metadata": {
        "id": "0qJ1-H9m_5Z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model = SVC(gamma='scale')\n",
        "# define grid\n",
        "balance = [{0:100,1:1}, {0:10,1:1}, {0:1,1:1}, {0:1,1:10}, {0:1,1:100}]\n",
        "param_grid = dict(class_weight=balance)\n",
        "# define evaluation procedure\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "# define grid search\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='roc_auc')\n",
        "\n",
        "for df in imputed_features:\n",
        "  X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 0:35], df['response'], test_size=0.2, random_state=0)\n",
        "  # execute the grid search\n",
        "  grid_result = grid.fit(X_train, y_train)\n",
        "  # report the best configuration\n",
        "  print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "  # report all configurations\n",
        "  means = grid_result.cv_results_['mean_test_score']\n",
        "  stds = grid_result.cv_results_['std_test_score']\n",
        "  params = grid_result.cv_results_['params']\n",
        "  for mean, stdev, param in zip(means, stds, params):\n",
        "      print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "id": "XK2O0SAil6Ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost "
      ],
      "metadata": {
        "id": "RdtRB2_w29RB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# SMOTE\n",
        "over = SMOTE(sampling_strategy=0.35)\n",
        "under = RandomUnderSampler(sampling_strategy=1)\n",
        "steps = [('o', over), ('u', under)]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "\n",
        "# Hyperparameters\n",
        "hyperparameter_grid = {\n",
        "    'n_estimators': [100, 500, 900, 1100, 1500],\n",
        "    'max_depth': [2, 3, 5, 10, 15],\n",
        "    'learning_rate': [0.05, 0.1, 0.15, 0.20],\n",
        "    'min_child_weight': [1, 2, 3, 4]\n",
        "    }\n",
        "\n",
        "model = XGBClassifier()\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=hyperparameter_grid, n_jobs=-1, cv=cv, scoring='roc_auc',error_score=0)\n",
        "\n",
        "for df in imputed_features:\n",
        "  X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 0:35], df['response'], test_size=0.2, random_state=0)\n",
        "  X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
        "\n",
        "  grid_result = grid_search.fit(X_train, y_train)\n",
        "  grid_predict = grid_search.predict(X_test)\n",
        "\n",
        "  # summarize results\n",
        "  print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "  print(confusion_matrix(y_test, grid_predict))\n",
        "  print(classification_report(y_test, grid_predict))"
      ],
      "metadata": {
        "id": "A27tPPMMRJhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "I3JKdx8O4p5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "def model_RF(fdf, response):\n",
        "  # Pull the correct resposne variable from the dataframe\n",
        "  y = main_df[response]\n",
        "  # Remove all rows with missing observations\n",
        "  X = fdf\n",
        "  X['y'] = y\n",
        "  X = fdf.dropna()\n",
        "  # Split data into test and trian\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X.iloc[:, 0:35], X.iloc[: , -1], test_size=0.20, random_state=0)\n",
        "  # Implement the model\n",
        "  regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
        "  regressor.fit(X_train, y_train)\n",
        "  y_pred = regressor.predict(X_test)\n",
        "\n",
        "  #use model to predict probability that given y value is 1\n",
        "  y_pred_proba = regressor.predict_proba(X_test)[::,1]\n",
        "\n",
        "  #calculate AUC of model\n",
        "  auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
        "\n",
        "  #print AUC score\n",
        "  print(auc)\n",
        "\n",
        "  # Calculate F-score\n",
        "  report = classification_report(y_test, y_pred)\n",
        "  print(report)\n",
        "\n",
        "  return y_pred"
      ],
      "metadata": {
        "id": "x5u3tH-14vNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Imports"
      ],
      "metadata": {
        "id": "HBvKTEZ5UUZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "6Ls5dT7oUYHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline"
      ],
      "metadata": {
        "id": "LWqwTTKk7v9v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imputation and Target Variable Selection"
      ],
      "metadata": {
        "id": "9liHjz7i9nf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compare_denisty(\"CPH_EV_AGE_CALC\",featuresKNN)"
      ],
      "metadata": {
        "id": "Y18vqJ-RKnND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New workflow"
      ],
      "metadata": {
        "id": "n9cE1mHW9sCK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split"
      ],
      "metadata": {
        "id": "dI43cWj4blmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter to only select basline event types\n",
        "main_df['CPH_EV_EVENT_TYPE'] = df_raw['CPH_EV_EVENT_TYPE']\n",
        "main_df_base = main_df[main_df['CPH_EV_EVENT_TYPE'] == 'Baseline']\n",
        "main_df_base = main_df_base.iloc[: , :-1]"
      ],
      "metadata": {
        "id": "lzCDMHkmcXCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop to check for boolean columns\n",
        "for column in main_df_base:\n",
        "  if main_df_base[column].max() == 1 and main_df_base[column].min() == 0:\n",
        "    main_df_base[column] = main_df_base[column].astype(bool)"
      ],
      "metadata": {
        "id": "Kp5ovn6Fep_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_df_base.dtypes"
      ],
      "metadata": {
        "id": "ui-qdgc8gCc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(main_df_base.iloc[:, 0:35], main_df_base['response_3a'], test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "k5eF8jShbPwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imputing"
      ],
      "metadata": {
        "id": "-PBHB5Ohbsb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_imputed = nan2mice(X_train)\n",
        "X_test_imputed = nan2mice(X_test)"
      ],
      "metadata": {
        "id": "1CEKOcp_bsB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scaling "
      ],
      "metadata": {
        "id": "Eak0dOKfeRe7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "rs = RobustScaler()\n",
        "\n",
        "to_scale_train = X_train_imputed.select_dtypes(include=[np.float64])\n",
        "to_scale_test = X_train_imputed.select_dtypes(include=[np.float64])\n",
        "\n",
        "# standardization of dependent variables\n",
        "X_train_imputed_scaled = rs.fit_transform(to_scale_train)\n",
        "X_test_imputed_scaled = rs.fit_transform(to_scale_test)"
      ],
      "metadata": {
        "id": "jtEdBj6zeUVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_df_train = pd.DataFrame(X_train_imputed_scaled)\n",
        "x_df_train[35] = y_train\n",
        "x_df_train.dropna(inplace=True)\n",
        "\n",
        "x_df_test = pd.DataFrame(X_test_imputed_scaled)\n",
        "x_df_test[35] = y_test\n",
        "x_df_test.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "knpMhRKFg8u_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Imputation"
      ],
      "metadata": {
        "id": "fzUaEDdhi1ZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stub_df = pd.DataFrame(columns=['CPH_EV_AGE_CALC', 'TBL.PATIENT.INFO..PI_BL_GENDER', 'CPH_EV_CI_BMI_CALC', \n",
        "                         'TBL.ALL.EVENTS..AE_SF_ALCO_XS', 'insulin_resistance', 'hypertensive', 'waist_to_hip_ratio',\n",
        "                         'idf_metabolic_syndrome', 'eGFR', 'dyslipidaemia', 'fibroscan_stiffness_reliable',\n",
        "                         'TBL.ALL.EVENTS..AE_BR_ALT_iuL',\n",
        "                         'TBL.ALL.EVENTS..AE_BR_AST_iuL', 'TBL.ALL.EVENTS..AE_BR_GGT_iuL',\n",
        "                         'TBL.ALL.EVENTS..AE_BR_FERR_ugL',\n",
        "                         'TBL.ALL.EVENTS..AE_BR_PLT_109L', 'TBL.ALL.EVENTS..AE_BR_CREAT_umolL_CALC',\n",
        "                         'TBL.ALL.EVENTS..AE_BR_STG_mmolL_CALC',\n",
        "                         'TBL.ALL.EVENTS..AE_BR_ALBU_gL_CALC', 'TBL.ALL.EVENTS..AE_BR_BILI_umolL_CALC',\n",
        "                         'TBL.ALL.EVENTS..AE_BR_IGA',\n",
        "                         'TBL.ALL.EVENTS..AE_CD_OSA', 'LIT_NB_CK18_M30', 'LIT_NB_CK18_M65', 'LIT_NB_PRO_C3', 'LIT_NB_PRO_C6',\n",
        "                          'LIT_NB_ELF', 'FIB4', 'NFS', 'APRI', 'ADAPT', 'FIBC3', 'ABC3D', 'BARD', 'AST_ALT_Ratio'])"
      ],
      "metadata": {
        "id": "NLEvIsI3MKZQ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stub_df"
      ],
      "metadata": {
        "id": "DS8-_yNfLDAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stub_df"
      ],
      "metadata": {
        "id": "D9WF1uxo7d2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import datetime\n",
        "# Used for analytics\n",
        "imputes = 0\n",
        "# Max absolute time difference - 6 Months\n",
        "# Add date and paitent identifier and event type\n",
        "main_df['CPH_ADM_BIOPSY_EVENT_DATE'] = df_raw['CPH_ADM_BIOPSY_EVENT_DATE']\n",
        "main_df['SPIC'] = df_raw['SPIC']\n",
        "main_df['CPH_EV_EVENT_TYPE'] = df_raw['CPH_EV_EVENT_TYPE']\n",
        "# Drop observations with no date\n",
        "main_df = main_df[main_df['CPH_ADM_BIOPSY_EVENT_DATE'].notna()]\n",
        "# Group data by paitnet ID\n",
        "main_df_grouped = main_df.groupby('SPIC')\n",
        "# Loop over the agregated data\n",
        "for group_name, df_group in main_df_grouped:\n",
        "  # Remove any duplicate rows\n",
        "  df_group = df_group.drop_duplicates()\n",
        "  # Sort the group based upon date\n",
        "  df_group = df_group.sort_values(by=['CPH_ADM_BIOPSY_EVENT_DATE'])\n",
        "  # Select the baseline observations\n",
        "  baseline_row = df_group.loc[df_group['CPH_EV_EVENT_TYPE'] == \"Baseline\"]\n",
        "  # If baseline row is non existant tell user\n",
        "  if baseline_row.empty:\n",
        "    print('No baseline for paitent: ' + df_group['SPIC'].item())\n",
        "  # Add basleine row to dataframe  \n",
        "  elif df_group.shape[0] <= 1:\n",
        "    stub_df = pd.concat([stub_df, baseline_row], ignore_index=True)\n",
        "  # Only select data to impute that has multiple observations\n",
        "  elif df_group.shape[0] > 1 :\n",
        "    # Selects date of baseline observation\n",
        "    start_date = baseline_row['CPH_ADM_BIOPSY_EVENT_DATE']\n",
        "    # Convert from series to datetime\n",
        "    start_date = datetime.datetime(start_date.dt.year,start_date.dt.month, start_date.dt.day)\n",
        "    # Calculate absoulte time differenance\n",
        "    df_group['Time Difference'] = abs(df_group['CPH_ADM_BIOPSY_EVENT_DATE'] - start_date)\n",
        "    # Remove all rows where time difference is to large to impute\n",
        "    df_group = df_group.loc[df_group['Time Difference'] < datetime.timedelta(days=200)]\n",
        "    # Check again to see if any data is imputeable\n",
        "    if df_group.shape[0] > 1:\n",
        "      # Select relevant data to impute\n",
        "      baseline_x = baseline_row.iloc[:, 0:35]\n",
        "      # for each column in the baseline row \n",
        "      for (columnName, columnData) in baseline_x.iteritems():\n",
        "        # Select value of current observation\n",
        "        val = columnData.item()\n",
        "        # If value is NaN\n",
        "        if np.isnan(val):\n",
        "          # For all other observations of the same paitent\n",
        "          for i in range(df_group.shape[0]-1):\n",
        "            # Select next observation \n",
        "            next = df_group.iloc[i+1]\n",
        "            new_val = next[columnName].item()\n",
        "            # If next value is NaN move on\n",
        "            if np.isnan(new_val):\n",
        "              break\n",
        "            # If next value is not NaN add to baseline observation\n",
        "            else:\n",
        "              columnData.item = new_val\n",
        "              imputes = imputes + 1\n",
        "              print('Imputing: ' + columnName + ' With: ' + str(new_val))\n",
        "    else:\n",
        "      print('Time difference to large for paitent: ' + df_group['SPIC'].item())\n",
        "  # Select new imputed basline\n",
        "  baseline_row = df_group.loc[df_group['CPH_EV_EVENT_TYPE'] == \"Baseline\"]\n",
        "  stub_df = pd.concat([stub_df, baseline_row], ignore_index=True)\n",
        "  # Reomve duplicates\n",
        "  stub_df = stub_df.drop_duplicates()"
      ],
      "metadata": {
        "id": "rSiYl7UyZhz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stub_df.drop_duplicates()"
      ],
      "metadata": {
        "id": "V37uJUmbordA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}